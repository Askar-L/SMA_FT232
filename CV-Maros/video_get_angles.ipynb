{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:45:46.508826Z",
     "start_time": "2023-12-15T05:45:45.657423Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Constants\n",
    "## For styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:45:46.662881Z",
     "start_time": "2023-12-15T05:45:46.504119Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = [(255,0,0), (127,0,255), (0,127,0), (0,127,255)]\n",
    "line_padding = [0.7, 1.5,1.5,1.5]\n",
    "\n",
    "font_scale = 1\n",
    "text_position_cnt = (100, 100)\n",
    "text_position_time = (100, 120)\n",
    "\n",
    "output_folder_video = \"../output/video\"\n",
    "output_folder_csv = \"../output/csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## For algorithm tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:45:46.853420Z",
     "start_time": "2023-12-15T05:45:46.687039Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Are for optime\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "threshold_area_size = [80, 20, 10, 40]\n",
    "video_path = \"../IMG_7102.MOV\"\n",
    "frame_shift = 500\n",
    "set_fps = 150 # I dont know if its work\n",
    "\n",
    "video_name = \"test_01_my_hand\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:45:47.207408Z",
     "start_time": "2023-12-15T05:45:47.053870Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add text overlay into video frame\n",
    "def add_text_to_frame(frame, text, position=(30, 30), font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=0.2, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"\n",
    "    Add text to a frame.\n",
    "\n",
    "    Parameters:\n",
    "    - frame (numpy.ndarray): Input frame.\n",
    "    - text (str): Text to be added to the frame.\n",
    "    - position (tuple): Position of the text (x, y).\n",
    "    - font (int): Font type.\n",
    "    - font_scale (float): Font scale.\n",
    "    - color (tuple): Text color (B, G, R).\n",
    "    - thickness (int): Text thickness.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Frame with added text.\n",
    "    \"\"\"\n",
    "    frame_with_text = frame.copy()\n",
    "    cv2.putText(frame_with_text, text, position, font, font_scale, color, thickness)\n",
    "    return frame_with_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:45:47.386030Z",
     "start_time": "2023-12-15T05:45:47.234415Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_angle(line1, line2):\n",
    "    # Convert lines to numpy arrays\n",
    "    line1 = np.array(line1)\n",
    "    line2 = np.array(line2)\n",
    "\n",
    "    # Calculate the vectors corresponding to the lines\n",
    "    vector1 = line1[1] - line1[0]\n",
    "    vector2 = line2[1] - line2[0]\n",
    "\n",
    "    # Calculate the dot product and cross product of the vectors\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    cross_product = np.cross(vector1, vector2)\n",
    "\n",
    "    # Calculate the magnitudes of the vectors\n",
    "    magnitude1 = np.linalg.norm(vector1)\n",
    "    magnitude2 = np.linalg.norm(vector2)\n",
    "\n",
    "    # Calculate the cosine of the angle between the vectors\n",
    "    cosine_theta = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "    # Determine the sign of the dot product to determine the direction\n",
    "    if dot_product > 0:\n",
    "        angle_radians = np.arccos(cosine_theta)\n",
    "        # Convert the angle to degrees\n",
    "        angle_degrees = 180 - np.degrees(angle_radians)\n",
    "        # Adjust angle for the cross product sign\n",
    "        if cross_product < 0:\n",
    "            angle_degrees = 360 - angle_degrees\n",
    "    else:\n",
    "        angle_radians = np.arccos(cosine_theta)\n",
    "        # Convert the angle to degrees\n",
    "        angle_degrees = np.degrees(angle_radians)\n",
    "\n",
    "    return angle_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:45:47.905496Z",
     "start_time": "2023-12-15T05:45:47.743842Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_vector(point1, point2):\n",
    "    return np.array(point2) - np.array(point1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:45:48.086427Z",
     "start_time": "2023-12-15T05:45:47.924390Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def segment_marker_by_color(frame_tmp):\n",
    "    # Input must be a frame in the cielab color model from the OpenCV function\n",
    "\n",
    "    # Extract color channels\n",
    "    L_channel = frame_tmp[:, :, 0]\n",
    "    a_channel = frame_tmp[:, :, 1]\n",
    "    b_channel = frame_tmp[:, :, 2]\n",
    "\n",
    "    # Color segmentation using NumPy array operations\n",
    "    marker_blue = (a_channel > 140) & (a_channel < 170) & (b_channel > 160)\n",
    "    marker_pink = (a_channel > 175) & (b_channel < 80)\n",
    "    marker_green = (a_channel < 120) & (b_channel > 130)\n",
    "    marker_yellow = (a_channel > 80) & (a_channel < 120) & (b_channel > 90) & (b_channel < 110)\n",
    "\n",
    "    return marker_blue, marker_pink, marker_green, marker_yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:45:48.596283Z",
     "start_time": "2023-12-15T05:45:48.427147Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main_function(frame, swap):\n",
    "    # Convert the input frame to the CIELAB color space\n",
    "    cielab_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2Lab)\n",
    "\n",
    "    # Segment markers by color in the CIELAB color space\n",
    "    marker_blue, marker_pink, marker_green, marker_yellow = segment_marker_by_color(cielab_frame)\n",
    "\n",
    "    # Create a stack of masks for each color marker\n",
    "    masks = np.stack([marker_blue, marker_pink, marker_green, marker_yellow], axis=0)\n",
    "\n",
    "    # Define color names for visualization\n",
    "    colors_name = [\"blue\", \"pink\", \"green\", \"yellow\"]\n",
    "\n",
    "    # Initialize a list to store points per frame\n",
    "    point_per_frame = []\n",
    "\n",
    "    # Set the line padding value\n",
    "    line_pad = 5  # Adjust this value as needed\n",
    "\n",
    "    # Initialize the direction vector for the first line\n",
    "    direction_vector_0_1 = None\n",
    "\n",
    "    # Iterate over each color marker\n",
    "    for mask, thr, color, color_name, direction_vector in zip(\n",
    "            masks, threshold_area_size, colors, colors_name, [direction_vector_0_1, None, None, None]\n",
    "    ):\n",
    "        # Convert the mask to uint8\n",
    "        mask = np.uint8(mask)\n",
    "\n",
    "        # Find connected components in the mask\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "\n",
    "        # Filter regions based on area threshold\n",
    "        filtered_regions = [index for index, stat in enumerate(stats[1:]) if stat[4] >= thr]\n",
    "\n",
    "        # Initialize a list to store points per mask\n",
    "        point_per_mask = []\n",
    "\n",
    "        # Iterate over filtered regions in the mask\n",
    "        for idx, index in enumerate(filtered_regions):\n",
    "            # Access region properties from the stats array\n",
    "            left, top, width, height, area = stats[index + 1]\n",
    "\n",
    "            # Calculate the centroid\n",
    "            centroid_x, centroid_y = int(left + width / 2), int(top + height / 2)\n",
    "\n",
    "            # Append the centroid to the list of points for the mask\n",
    "            point_per_mask.append((centroid_x, centroid_y))\n",
    "\n",
    "        # Visualize circles for each point in the mask\n",
    "        for idx, point in enumerate(point_per_mask):\n",
    "            cv2.circle(frame, (point[0], point[1]), radius=idx * 10, color=color, thickness=5)\n",
    "\n",
    "        # Visualize circles for each point with increased radius\n",
    "        for idx, point in enumerate(point_per_mask):\n",
    "            cv2.circle(frame, (point[0], point[1]), radius=idx * 10 + 10, color=color, thickness=5)\n",
    "\n",
    "        # If direction vector is not initialized, calculate it from the first two points\n",
    "        if direction_vector is None:\n",
    "            direction_vector = calculate_vector(point_per_mask[1], point_per_mask[0])\n",
    "\n",
    "        # Calculate points for the line based on the direction vector and line padding\n",
    "        point1 = (\n",
    "            int(point_per_mask[1][0] - line_pad * direction_vector[0]),\n",
    "            int(point_per_mask[1][1] - line_pad * direction_vector[1]),\n",
    "        )\n",
    "        point2 = (\n",
    "            int(point_per_mask[0][0] + line_pad * direction_vector[0]),\n",
    "            int(point_per_mask[0][1] + line_pad * direction_vector[1]),\n",
    "        )\n",
    "\n",
    "        # Visualize the line connecting the two points\n",
    "        cv2.line(frame, point1, point2, color, 3)\n",
    "\n",
    "        # Append the points for the current mask to the list of points per frame\n",
    "        point_per_frame.append(point_per_mask)\n",
    "\n",
    "    # Calculate angles between consecutive lines\n",
    "    angle_0 = calculate_angle(point_per_frame[0], point_per_frame[1])\n",
    "    angle_1 = calculate_angle(point_per_frame[1], point_per_frame[2])\n",
    "    angle_2 = calculate_angle(point_per_frame[2], point_per_frame[3])\n",
    "\n",
    "    # Add text annotations to the frame with calculated angles\n",
    "    frame = add_text_to_frame(frame, \"ANGLE 0: {}\".format(int(angle_0)), position=(1000, 810), font_scale=0.5, thickness=2, color=(255, 255, 0))\n",
    "    frame = add_text_to_frame(frame, \"ANGLE 1: {}\".format(int(angle_1)), position=(1000, 830), font_scale=0.5, thickness=2, color=(255, 255, 0))\n",
    "    frame = add_text_to_frame(frame, \"ANGLE 2: {}\".format(int(angle_2)), position=(1000, 850), font_scale=0.5, thickness=2, color=(255, 255, 0))\n",
    "\n",
    "    return frame, angle_0, angle_1, angle_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:45:48.762240Z",
     "start_time": "2023-12-15T05:45:48.609500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def store_video(frames, output_path, fps):\n",
    "    # Function to store the video with updated frames\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
    "    height, width, _ = frames[0].shape\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Main logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T05:46:12.446282Z",
     "start_time": "2023-12-15T05:45:49.278702Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3.532] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (2386) handleMessage OpenCV | GStreamer warning: your GStreamer installation is missing a required plugin\n",
      "[ WARN:0@3.532] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (2402) handleMessage OpenCV | GStreamer warning: Embedded video playback halted; module uridecodebin0 reported: Your GStreamer installation is missing a plug-in.\n",
      "[ WARN:0@3.532] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (1356) open OpenCV | GStreamer warning: unable to start pipeline\n",
      "[ WARN:0@3.532] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Use the original frame instead of creating a copy\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m frame, angle_0, angle_1, angle_2  \u001b[38;5;241m=\u001b[39m \u001b[43mmain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Add text to the frame\u001b[39;00m\n\u001b[1;32m     27\u001b[0m frame \u001b[38;5;241m=\u001b[39m add_text_to_frame(frame, \u001b[38;5;28mstr\u001b[39m(cnt), position\u001b[38;5;241m=\u001b[39mtext_position_cnt, font_scale\u001b[38;5;241m=\u001b[39mfont_scale)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mmain_function\u001b[0;34m(frame, swap)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# If direction vector is not initialized, calculate it from the first two points\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m direction_vector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     direction_vector \u001b[38;5;241m=\u001b[39m calculate_vector(\u001b[43mpoint_per_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, point_per_mask[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Calculate points for the line based on the direction vector and line padding\u001b[39;00m\n\u001b[1;32m     63\u001b[0m point1 \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mint\u001b[39m(point_per_mask[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m line_pad \u001b[38;5;241m*\u001b[39m direction_vector[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mint\u001b[39m(point_per_mask[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m line_pad \u001b[38;5;241m*\u001b[39m direction_vector[\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     66\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"../IMG_7102.MOV\")\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_shift)\n",
    "cap.set(cv2.CAP_PROP_FPS, set_fps)\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open the video file.\")\n",
    "    exit()\n",
    "\n",
    "# Create a window to display the frames\n",
    "cv2.namedWindow('Video Preview', cv2.WINDOW_NORMAL)\n",
    "\n",
    "measure = [] # for storing angles\n",
    "frames_to_store = []\n",
    "cnt = frame_shift # for storing frame count\n",
    "while True:\n",
    "    strt = time.time()\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Use the original frame instead of creating a copy\n",
    "    frame, angle_0, angle_1, angle_2  = main_function(frame, False)\n",
    "\n",
    "    # Add text to the frame\n",
    "    frame = add_text_to_frame(frame, str(cnt), position=text_position_cnt, font_scale=font_scale)\n",
    "\n",
    "    # Calculate and add time information\n",
    "    end = time.time()\n",
    "    frame = add_text_to_frame(frame, str(end - strt), position=text_position_time, font_scale=font_scale)\n",
    "    measure.append([cnt, angle_0,angle_1,angle_2])\n",
    "    cv2.imshow('Video Preview', frame)\n",
    "    frames_to_store.append(frame.copy())\n",
    "    cnt += 1\n",
    "    if cv2.waitKey(int(1000 / 1000)) & 0xFF == 27: # cv2.waitKey(1000) & 0xFF == ord('q')\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Store processed video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T06:00:21.996692Z",
     "start_time": "2023-12-13T06:00:15.533163Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(<unknown>:18668): GStreamer-CRITICAL **: 15:00:15.501: gst_element_make_from_uri: assertion 'gst_uri_is_valid (uri)' failed\n",
      "[ WARN:0@1497.422] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (2180) open OpenCV | GStreamer warning: cannot link elements\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "2023-12-13 15:00:21.962 python[18668:25209042] WARNING: -finishWriting should not be called on the main thread.\n"
     ]
    }
   ],
   "source": [
    "# Store the video with updated frames\n",
    "output_video_path = os.path.join(output_folder_video,f\"{video_name}.mp4\")  # Set the desired output video path\n",
    "store_video(frames_to_store, output_video_path, set_fps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Store csv - raw_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T07:55:38.001957Z",
     "start_time": "2023-12-13T07:55:37.950528Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>angle_0</th>\n",
       "      <th>angle_1</th>\n",
       "      <th>angle_2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>108.411997</td>\n",
       "      <td>95.616618</td>\n",
       "      <td>107.868928</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501</td>\n",
       "      <td>108.070983</td>\n",
       "      <td>94.565037</td>\n",
       "      <td>109.502839</td>\n",
       "      <td>3.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>108.070983</td>\n",
       "      <td>95.416016</td>\n",
       "      <td>109.118753</td>\n",
       "      <td>3.346667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>108.132717</td>\n",
       "      <td>95.416016</td>\n",
       "      <td>108.271437</td>\n",
       "      <td>3.353333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>109.105193</td>\n",
       "      <td>93.530827</td>\n",
       "      <td>109.122416</td>\n",
       "      <td>3.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1083</td>\n",
       "      <td>192.166393</td>\n",
       "      <td>189.383085</td>\n",
       "      <td>187.626994</td>\n",
       "      <td>7.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>1084</td>\n",
       "      <td>192.166393</td>\n",
       "      <td>189.383085</td>\n",
       "      <td>186.952957</td>\n",
       "      <td>7.226667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1085</td>\n",
       "      <td>192.220577</td>\n",
       "      <td>187.434327</td>\n",
       "      <td>189.575753</td>\n",
       "      <td>7.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>1086</td>\n",
       "      <td>192.220577</td>\n",
       "      <td>188.010393</td>\n",
       "      <td>188.325650</td>\n",
       "      <td>7.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>1087</td>\n",
       "      <td>191.260977</td>\n",
       "      <td>188.915809</td>\n",
       "      <td>189.657870</td>\n",
       "      <td>7.246667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     frame     angle_0     angle_1     angle_2      time\n",
       "0      500  108.411997   95.616618  107.868928  3.333333\n",
       "1      501  108.070983   94.565037  109.502839  3.340000\n",
       "2      502  108.070983   95.416016  109.118753  3.346667\n",
       "3      503  108.132717   95.416016  108.271437  3.353333\n",
       "4      504  109.105193   93.530827  109.122416  3.360000\n",
       "..     ...         ...         ...         ...       ...\n",
       "583   1083  192.166393  189.383085  187.626994  7.220000\n",
       "584   1084  192.166393  189.383085  186.952957  7.226667\n",
       "585   1085  192.220577  187.434327  189.575753  7.233333\n",
       "586   1086  192.220577  188.010393  188.325650  7.240000\n",
       "587   1087  191.260977  188.915809  189.657870  7.246667\n",
       "\n",
       "[588 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_angle = pd.DataFrame(data=measure, columns=[\"frame\", \"angle_0\", \"angle_1\", \"angle_2\"])\n",
    "df_angle[\"time\"] = df_angle[\"frame\"] / set_fps\n",
    "df_angle.to_csv(os.path.join(output_folder_csv,f\"{video_name}.csv\"), index=False)\n",
    "df_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
